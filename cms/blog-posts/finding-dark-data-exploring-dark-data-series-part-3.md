---
f_prev-text: >-
  Understanding where your unused or underutilized data resides is the first
  step to unlocking its value and transforming it into a valuable asset.
title: 'Finding Dark Data (Exploring Dark Data Series – Part 3) '
f_image:
  url: /assets/external/63e8c4b8eaf853174858cded_header.jpg
  alt: null
slug: finding-dark-data-exploring-dark-data-series-part-3
f_ref: cms/blog-category/ecm.md
updated-on: '2023-02-12T11:31:22.589Z'
created-on: '2023-02-12T11:09:43.283Z'
published-on: '2023-10-18T19:32:14.085Z'
layout: '[blog-posts].html'
tags: blog-posts
---

![](/assets/external/63e8c4b8eaf853174858cded_header.jpg)

In the third installment of our "Exploring Dark Data" series, we focus on the task of finding Dark Data. Understanding where your unused or underutilized data resides is the first step to unlocking its value and transforming it into a valuable asset.

In the digital age, data is power. Organizations across industries are constantly collecting and storing massive amounts of information, ranging from personal details to confidential business insights. While having access to such data is certainly valuable, it also opens up opportunities for exploitation by malicious actors. To mitigate this risk, organizations must identify and understand their "dark data." It's often data that an organization doesn't know they have or they don't know how sensitive it is.

The discovery and classification of dark data is an important step in making it usable for decision-making. By knowing where the sensitive information is stored, who has access to it, and when abuse occurs, organizations can take action to prevent it. The security teams of these organizations need to know all of this information to ensure that the data is protected.

The process of discovering and classifying dark data is essential for organizations seeking to protect their information and make the most of their data assets. It allows organizations to gain new insights, make informed decisions, and stay ahead in the rapidly evolving landscape of business and technology. With the increasing importance of data in decision-making, organizations must take the necessary steps to identify and classify their dark data in order to fully capitalize on its value.

Assessing and revising an organization's dark data can be approached in two ways. On the one hand, independent consultants specializing in data analysis can review a company's data environment and conduct thorough assessments of unclassified and uncatalogued data. On the other hand, organizations can utilize data analytics tools to perform self-reviews of their data repositories. This option is often preferred, as it provides the organization with a complete understanding of its data and helps identify any potential security gaps or regulatory violations.

By conducting an internal review, organizations can gain a deeper and more accurate understanding of their data and its security status. They can identify who has access to what information, identify internal permissions, and detect any malicious or careless behavior that could place confidential data at risk. The use of data analytics solutions can provide a more comprehensive and precise view of an organization's data and clearly outline the steps needed to address any risks.

Ultimately, the choice between using an external consultant or conducting an internal review comes down to the organization's specific needs and goals. However, by using the right tools, an internal review can provide organizations with a more discerning and complete understanding of their data, enabling them to take the necessary steps to protect it and make the most of their data assets.

Organizations cannot fully understand the business value of their dark data or protect it appropriately until they have visibility into it. Tagging or cataloging hidden data is a crucial first step toward gaining that visibility. Without it, organizations cannot comply with data governance standards, meet regional regulatory requirements, provide robust security, or ensure data privacy for their customers and employees.

The lack of visibility into dark data can lead to significant challenges for organizations. For instance, they may be unable to comply with regulations and standards, which can result in hefty fines and legal penalties. The lack of visibility also makes it difficult to provide effective security and guarantee data privacy, which can harm a company's reputation and lead to the loss of customers and employees, and could even result in legal actions.

Creating a framework for tagging or cataloging dark data is essential for organizations seeking to understand the business value of their data and protect it effectively. With a clear understanding of their data, organizations can make informed decisions, comply with regulations, provide security and privacy, and ultimately unlock the full potential of their data assets. By taking these crucial steps, organizations can ensure that their data is protected, valuable, and accessible for years to come.

### Evaluating & Identifying Dark Data

There are six factors you can use to evaluate and identify dark data. It is important to use such evaluation factors and frameworks so that you won't be running blind in your quest to unearth dark data.

The following six factors will help information governance teams evaluate and identify dark data they have and highlight other issues with their data.

#### 1\. Data Staleness

![](/assets/external/63e8c816c21faa4918c25584_in-01.jpg)

Data staleness refers to the age of a dataset and how long it has been since it was last modified or updated. In evaluating and identifying dark data, organizations must assess the staleness of their data assets. A relevant question to ask would be, "When was the dataset last changed?"

Data that hasn't been altered for a substantial amount of time is considered stale. This can suggest that it is no longer useful or valuable to the organization. Evaluating staleness helps organizations rank their data assets and determine which ones to maintain, delete, or update for future use. This helps them make the most of their data by only utilizing the most recent and valuable information.

Stale data can also lead to data clutter and slow systems, which results in inefficiencies and higher costs. Regularly evaluating and updating data can improve data management processes and optimize the utilization of data assets. The objective is to maintain a balance between retaining relevant data and regularly updating or deleting stale data.

#### 2\. Low Popularity Score

![](/assets/external/63e8c8248b497e011346ed9b_in-02.jpg)

A low popularity score is a key indicator that a particular dataset is not widely used or trusted as a source of information. When evaluating dark data, it's important to assess the popularity score of each data asset. Organizations can do this by examining whether any pipelines, models, or business intelligence systems are relying on the asset.  

A low popularity score suggests that the data in question may not be critical to the organization's operations or decision-making processes. This could mean that the data is not needed, or it may not be of the highest quality or accuracy. In such cases, the organization may choose to delete or archive the data to avoid cluttered data stores and improve data management processes.

On the other hand, if the data is still in use or relevant, a low popularity score could be a result of a lack of knowledge about the data's existence or value. This highlights the need for organizations to improve data cataloging and documentation practices to ensure that all data assets are effectively managed and leveraged. In short, evaluating the popularity score of dark data is a crucial step in determining the importance of data assets and making informed decisions about their management and utilization.

#### 3\. Data Provenance is Missing

![](/assets/external/63e8c8418b497e5dd746f4c1_in-03.jpg)

Data provenance can be critical in determining the quality, trustworthiness, and value of a dataset. When data is missing its provenance, it can be challenging to determine where it came from and how it was processed. In evaluating your assets, you may want to ask yourself questions like:

1.) Is this dataset siloed and not used in any other parts of your organization?

2.) What are the upstream and downstream applications that use this data, if any?

Answering these questions will help you determine the importance and value of an asset and if it is worth investing in preserving or discarding. Moreover, it provides insight into whether the data is part of a broader data landscape and whether it is integrated into your organization's processes and decision-making.

#### 4\. Poor Data Quality

![](/assets/external/63e8c85cc21faa42efc25ac9_in-04.jpg)

Poor data quality can hinder an organization's ability to derive meaningful insights from its data. Low-quality datasets that are filled with null or duplicate values, have incorrect patterns or are missing data, which can lead to incomplete or inaccurate results. When evaluating these datasets, it's important to determine whether they can be improved or if it's best to simply discard them. Assessing the quality of your data is crucial in making sure it can be relied upon for making informed decisions.  

#### 5\. Data Redundancy

![](/assets/external/63e8c868f17305a46e04de2b_in-05.jpg)

Data redundancy can significantly impact an organization's data storage and management efforts. Having multiple copies of the same data stored in different systems can lead to confusion, waste of resources, and a decrease in overall data accuracy. To address this issue, it's crucial to regularly employ machine learning (ML) techniques such as data similarity discovery. These techniques enable organizations to detect and eliminate redundant data, thereby streamlining their data storage and management processes. Implementing such techniques can also lead to more efficient use of storage space, which can positively impact the organization's bottom line. An enterprise tech consultant can assist with this, as they have the expertise and knowledge of the latest techniques to ensure an organization's data is managed in an optimal way.

#### 6\. Unclassified Data

![](/assets/external/63e8c8758c099712c9c0646f_in-06.jpg)

Data classification is a crucial step in any data management strategy, as it helps organizations identify sensitive and confidential information that requires special protection and management. Unclassified or untagged data can pose significant risks, as they may contain sensitive information that can lead to data breaches if not handled properly. Organizations should have a comprehensive process for data classification and review their data assets periodically to identify any unclassified data that may require special attention. By doing so, organizations can ensure that their sensitive data is properly managed and protected against potential security threats.

Part 3 of our series has shown you the ways to identify dark data in your enterprise. Stay tuned for [the next article](/blog-posts/4-tips-to-tackle-data-surplus-and-shortage-of-insights-from-a-problem-to-an-advantage-exploring-dark-data-series-part-4) where we will explore how to analyse more data and cut down the cost incurred by dark data.
